# aim for total-points around 800
# should always be high res enough to serve graphs, but not too high for storage overhead + runtime aggregations
# chunksize: ideally around 120 points (see go-tsz benchmarks) but no longer than 6h for simplicity
# for raw let's try to keep 6h of data in RAM to serve the standard dashboards without cassandra
# type       span-in-seconds   compression factor  retention   retention factor total-points  chunkspan points-per-chunk
# raw        [1]10~120         0                   26h         1                780-93600     600       5~60[~600]
# agg 10min  60*10   -> 600    5~60~[600]          9d          8.3              1296          21600     36
# agg 2h     60*60*2 -> 7200   12                  60+14=74d   8.2              888           21600     3
# agg 6h     60*60*6 -> 21600  3                   4y          19.8             5840          21600     1
# TODO update numchunks to 36 (6h)once everything tested well, now lower (30min) to spot issues earlier
# TODO update chunk retentions to 1 once https://github.com/raintank/metrictank/issues/65 is fixed
#
#
# -log-level 0=TRACE|1=DEBUG|2=INFO|3=WARN|4=ERROR|5=CRITICAL|6=FATAL (default 2)
cd /go/src/github.com/raintank/metrictank
go build
wait.sh cassandra:9042 elasticsearch:9200
# use this env var to trace GC data for gcvis and https://github.com/golang/go/issues/14812
#GODEBUG=gctrace=1,gcpacertrace=1
./metrictank \
	--chunkspan 10m \
	--numchunks 2 \
	--agg-settings 10m:6h:2:9d,2h:6h:2:74d,6h:6h:2:4y \
	--accounting-period 1min \
	--proftrigger-freq 1s \
	-log-level 2 \
	-config /etc/raintank/metrictank.ini \
	&>> /var/log/raintank/metrictank.log &
tail -f /var/log/raintank/metrictank.log
